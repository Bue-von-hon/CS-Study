저는 포기하지 않고 지속적인 원인 분석 및 코드 개선을 통해 데이터 처리 속도를 개선하여 연구사업 수행에 크게 이바지한 경험이 있습니다. 연구사업 중 2TB가 넘는 데이터를 6시간 이내로 끝내야 하는 과제가 있었습니다. 가장 큰 문제는 누구도 대학원 수준에서 2TB가 넘는 데이터를 처리한 경험이 없었고, 기존 알고리즘은 데이터를 처리하는데 365일이 넘게 걸리는 것이었습니다. 연구과제를 수행하는 사람들의 경험을 공유해가며 빠른 데이터 처리 성능을 위해 멀티 프로세싱을 도입하여 30일로 단축이 되었지만, 목표 시간에는 도달하지 못했습니다. 교수님께서는 제게 그 이상의 성능개선에는 어려움이 있다고 판단하여 다른 연구를 진행하도록 권유하셨습니다. 저는 포기하지 않고 2주 가까이 성능을 개선 사례의 논문을 집중적으로 공부한 결과, 데이터를 저장하고 처리하는 자료구조 및 알고리즘에 문제가 있었음을 알아낼 수 있었습니다. 제가 사용한 알고리즘은 두 데이터 집합을 하나씩 비교하여 합치는 알고리즘이었는데, 이는 작은 데이터에서는 크게 성능 차이가 나지 않지만, 데이터가 2TB가 넘는 데이터에서는 그에 비례하게 처리 속도 역시 늦어졌습니다. 트리 자료구조와 union-find 알고리즘을 이용하여 두 데이터 집합을 합치는데 단 두 번으로 줄일 수 있었습니다. 그 결과, 데이터 처리 속도 역시 대폭 개선되었고, 개선 시간은 30일에서 3시간 30분의 시간으로 데이터 처리 시간을 단축할 수 있었습니다.

끊임없는 원인 분석 및 아이디어 모색으로 문제를 해결했던 경험을 토대로, 다른 연구과제에서도 어려운 문제들이 부딪쳤을 때 포기하지 않고 계속 방법을 생각해내어 문제를 해결하였습니다. ****에서도 어려운 문제에 부딪쳤을 때 그 문제를 새로운 관점으로 끊임없이 해결방안을 제시하는 인재가 되겠습니다.